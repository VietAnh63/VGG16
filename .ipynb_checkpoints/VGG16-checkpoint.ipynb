{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Thêm thư viện\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from imutils import paths\n",
    "from keras.applications import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import load_img\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.applications import VGG16\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Flatten\n",
    "import numpy as np\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lấy các đường dẫn đến ảnh.\n",
    "image_path = list(paths.list_images('dataset/'))\n",
    "\n",
    "# Đổi vị trí ngẫu nhiên các đường dẫn ảnh\n",
    "random.shuffle(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đường dẫn ảnh sẽ là dataset/tên_phương_tiện/tên_ảnh ví dụ dataset/Bluebell/image_0241.jpg nên p.split(os.path.sep)[-2] sẽ lấy ra được tên phương tiện\n",
    "labels = [p.split(os.path.sep)[-2] for p in image_path]\n",
    "\n",
    "# Chuyển tên các loài hoa thành số\n",
    "le = LabelEncoder()\n",
    "labels = le.fit_transform(labels)\n",
    "\n",
    "# One-hot encoding\n",
    "lb = LabelBinarizer()\n",
    "labels = lb.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ảnh và resize về đúng kích thước mà VGG 16 cần là (224,224)\n",
    "list_image = []\n",
    "for (j, imagePath) in enumerate(image_path):\n",
    "    # Đọc ảnh dưới dạng PIL\n",
    "    image = load_img(imagePath, target_size=(224, 224))\n",
    "    # Chuyển ảnh về dạng Numpy\n",
    "    image = img_to_array(image)\n",
    "    # Thêm 1 chiều nữa cho ảnh (1,224,224,3)\n",
    "    # image = np.expand_dims(image, 0)\n",
    "    # Lấy giá trị điểm ảnh trừ đi giá trị trung bình của RGB\n",
    "    image = preprocess_input(image)   \n",
    "    list_image.append(image)\n",
    "    \n",
    "list_image = np.array(list_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/admin/.conda/envs/tensorflow_env/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Users/admin/.conda/envs/tensorflow_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "# Load model VGG 16 của ImageNet dataset, include_top=False để bỏ phần Fully connected layer ở cuối.\n",
    "baseModel = VGG16(weights='imagenet', include_top=False, input_tensor=Input(shape=(224, 224, 3)))\n",
    "\n",
    "# Xây thêm các layer\n",
    "# Lấy output của ConvNet trong VGG16\n",
    "fcHead = baseModel.output\n",
    "\n",
    "# Flatten trước khi dùng FCs\n",
    "fcHead = Flatten(name='flatten')(fcHead)\n",
    "\n",
    "# Thêm FC\n",
    "fcHead = Dense(256, activation='relu')(fcHead)\n",
    "\n",
    "# Droput để tránh overfitting , regularization tăng hàm phạt\n",
    "fcHead = Dropout(0.5)(fcHead)\n",
    "\n",
    "# Output layer với softmax activation\n",
    "fcHead = Dense(5, activation='softmax')(fcHead)\n",
    "\n",
    "# Xây dựng model bằng việc nối ConvNet của VGG16 và fcHead\n",
    "model = Model(inputs=baseModel.input, outputs=fcHead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chia traing set, test set tỉ lệ 80-20\n",
    "X_train, X_test, y_train, y_test = train_test_split(list_image, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# augmentation cho training data\n",
    "# Thêm dữ liệu cho data\n",
    "aug_train = ImageDataGenerator(rescale=1./255, rotation_range=30, width_shift_range=0.1, height_shift_range=0.1, shear_range=0.2, zoom_range=0.2, horizontal_flip=True, fill_mode='nearest')\n",
    "# augementation cho test\n",
    "aug_test= ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/admin/.conda/envs/tensorflow_env/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/2\n",
      "148/148 [==============================] - 523s 4s/step - loss: 2.1245 - acc: 0.5020 - val_loss: 0.7041 - val_acc: 0.6027\n",
      "Epoch 2/2\n",
      "148/148 [==============================] - 656s 4s/step - loss: 0.7948 - acc: 0.6970 - val_loss: 0.3462 - val_acc: 0.8812\n"
     ]
    }
   ],
   "source": [
    "# Đóng băng toàn bộ VGG\n",
    "for layer in baseModel.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "opt = RMSprop(0.001)\n",
    "model.compile(opt, 'categorical_crossentropy', ['accuracy'])\n",
    "num_Epoch = 2\n",
    "H = model.fit_generator(aug_train.flow(X_train, y_train, batch_size=10), \n",
    "                        steps_per_epoch=len(X_train)//10,\n",
    "                        validation_data=(aug_test.flow(X_test, y_test, batch_size=10)),\n",
    "                        validation_steps=len(X_test)//10,\n",
    "                        epochs=num_Epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "148/148 [==============================] - 1537s 10s/step - loss: 12.4088 - acc: 0.2284 - val_loss: 12.4589 - val_acc: 0.2270\n",
      "Epoch 2/2\n",
      "148/148 [==============================] - 1491s 10s/step - loss: 12.4916 - acc: 0.2250 - val_loss: 12.5561 - val_acc: 0.2210\n"
     ]
    }
   ],
   "source": [
    "# Mở đóng băng toàn bộ và train cùng các layer được thêm\n",
    "for layer in baseModel.layers:\n",
    "    layer.trainable = True\n",
    "    \n",
    "opt = RMSprop(0.001)\n",
    "model.compile(opt, 'categorical_crossentropy', ['accuracy'])\n",
    "num_Epoch = 2\n",
    "# steps_per_epoch : Số lần tính gradient trong 1 epoch\n",
    "# valadation_step: Tương tự nhưng trên tập validation\n",
    "# Đối với fit_generator cho phép bỏ qua những dữ liệu trùng nhau và có nhiều tuỳ biến\n",
    "H = model.fit_generator(aug_train.flow(X_train, y_train, batch_size=10), \n",
    "                        steps_per_epoch=len(X_train)//10,\n",
    "                        validation_data=(aug_test.flow(X_test, y_test, batch_size=10)),\n",
    "                        validation_steps=len(X_test)//10,\n",
    "                        epochs=num_Epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               6422784   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 1285      \n",
      "=================================================================\n",
      "Total params: 21,138,757\n",
      "Trainable params: 21,138,757\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "372/372 [==============================] - 132s 355ms/step\n",
      "Loss = 12.478525448870915\n",
      "Accuracy of VGG16 for Test set  = 0.22580645177313077\n"
     ]
    }
   ],
   "source": [
    "preds = model.evaluate(X_test, y_test)\n",
    "print (\"Loss = \" + str(preds[0]))\n",
    "print (\"Accuracy of VGG16 for Test set  = \" + str(preds[1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
